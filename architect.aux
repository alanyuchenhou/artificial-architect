\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Finished steps}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Basic hill climbing}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Hill climbing with random restart, learning and feedback}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The basic search process. The score is calculated with the model learned from a previously obtained data set.}}{2}}
\newlabel{fig:trace}{{1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The 2nd search process. The new energy consumption is obtained from the simulator's feedback.}}{3}}
\newlabel{fig:refined}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Optimization for latency}{3}}
\citation{chang2011libsvm}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The optimization process with latency as the metric during a single hill climbing}}{4}}
\newlabel{fig:latency}{{3}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Data standardization}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Regression SVM latency model accuracy evaluation}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Regression SVM latency model evaluation results for 4 kernels}}{5}}
\newlabel{tab:latency}{{1}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}Regression SVM power model accuracy evaluation}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Regression SVM power model evaluation results for 4 kernels}}{5}}
\newlabel{tab:power}{{2}{5}}
\citation{brochu2010tutorial}
\citation{demasiusing}
\@writefile{toc}{\contentsline {section}{\numberline {2}Next steps}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Network optimization for power latency product}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}More expressive design features}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}New learners: Boosted Regression Trees and LambdaMART}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Bayesian optimization and Guassian processes}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Study a Bayesian optimization for hardware design}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}New learning algorithm}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Learning algorithm tuning}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}Model oriented learning}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9}Large neighborhood and first-choice hill climbing}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.10}Small neighborhood and simulated annealing}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.11}Adaptive searching}{7}}
\citation{amoretti2014modeling}
\citation{jiang2013detailed}
\citation{ganguly2011scalable}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.12}Neighbor filtering}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.13}Program profiling}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Introduction}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Motivation and challenges}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Solution approach}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Results}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Problem setup}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Assumptions}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Task definition and formulation}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Network design specifications}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces 2 examples of 64 node networks with different link counts}}{10}}
\newlabel{fig:networks}{{4}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Network design features}{10}}
\citation{bienia2011benchmarking}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces The network design features}}{11}}
\newlabel{tab:features}{{3}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Network design quality}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Task environment}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Performance measure}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Environment}{11}}
\citation{russell1995modern}
\citation{joachims2006training}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces The characteristics of the simulator}}{12}}
\newlabel{tab:environment}{{4}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Actuators and sensors}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {6}System design}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Critic}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Learning element}{12}}
\citation{russell1995modern}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Performance element}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Solution approach: optimization process}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Naive approach: basic hill climbing}{13}}
\bibstyle{plain}
\bibdata{architect}
\bibcite{amoretti2014modeling}{1}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Refinement: random restart, learning and feedback}{14}}
\bibcite{bienia2011benchmarking}{2}
\bibcite{brochu2010tutorial}{3}
\bibcite{chang2011libsvm}{4}
\bibcite{demasiusing}{5}
\bibcite{ganguly2011scalable}{6}
\bibcite{jiang2013detailed}{7}
\bibcite{joachims2006training}{8}
\bibcite{russell1995modern}{9}
